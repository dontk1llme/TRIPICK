{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzmAm6BBlN24"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8_Hn7CiDFPs",
        "outputId": "1b1e785f-641d-4957-b05a-92b4a944e7a3"
      },
      "outputs": [],
      "source": [
        "# !pip install pmdarima\n",
        "# !pip install prophet\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import pandas as pd\n",
        "import pandas_datareader.data as pdr\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import seaborn as sns\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "%matplotlib inline\n",
        "\n",
        "import pmdarima as pm\n",
        "from pmdarima.arima import auto_arima\n",
        "\n",
        "from prophet import Prophet\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tsa.stattools import acf, pacf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from datetime import datetime\n",
        "from matplotlib.dates import MonthLocator, DateFormatter\n",
        "\n",
        "# Google Drive 연동\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "\n",
        "# 데이터 불러오기\n",
        "data = pd.read_csv(\"/content/gdrive/MyDrive/Colab Notebooks/bigdata/remove_city_under_5000_2.csv\")\n",
        "\n",
        "# 날짜 정보를 활용하여 연도와 월을 하나의 날짜 형식으로 변환\n",
        "data['date'] = pd.to_datetime(data[['year', 'month']].assign(day=1))\n",
        "\n",
        "data = data[['city', 'date', 'people']]\n",
        "data.set_index('date', inplace=True)\n",
        "\n",
        "train_data = data[['city', 'people']]\n",
        "\n",
        "cities = data['city'].unique()\n",
        "\n",
        "# 각 도시의 모델을 저장할 딕셔너리 생성\n",
        "city_models = {}\n",
        "\n",
        "# 빈 DataFrame 생성\n",
        "result_df = pd.DataFrame(columns=['City', 'Date', 'People'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NEJmVClODIK3",
        "outputId": "9ec92f2d-1af1-4958-e68b-520c941b89aa"
      },
      "outputs": [],
      "source": [
        "for city in tqdm(cities):\n",
        "  city_data = train_data[train_data['city'] == city]['people']\n",
        "\n",
        "  if len(city_data) < 60 : continue\n",
        "\n",
        "  city_data_diff = city_data.diff().dropna()\n",
        "\n",
        "  city_data.plot()\n",
        "  city_data_diff.plot()\n",
        "\n",
        "  current_date = datetime.now()\n",
        "  year = int(str(current_date).split(\"-\")[0])\n",
        "  month = int(str(current_date).split(\"-\")[1])\n",
        "\n",
        "  end_year = year + (month+5)//12\n",
        "  end_month = 12 if (month+6)%12 == 0 else (month+6)%12\n",
        "\n",
        "  start_dt = datetime(year, month, 1)\n",
        "  end_dt = datetime(end_year, end_month, 1)\n",
        "\n",
        "  date_range = pd.date_range(start=start_dt, end=end_dt, freq='MS')\n",
        "\n",
        "  loaded_model = city_models[city]\n",
        "\n",
        "  res = sm.tsa.statespace.SARIMAX(city_data, order=(0, 1, 0), seasonal_order=(2, 1, 1, 12), enforce_stationarity=True, enforce_invertibility=True).fit()\n",
        "  prediction = res.get_forecast(steps=len(date_range))\n",
        "\n",
        "  # 모델 저장\n",
        "  city_models[city] = res\n",
        "\n",
        "  predicted_value = prediction.predicted_mean\n",
        "\n",
        "  # 최근 12개월 평균 여행객 수 계산\n",
        "  recent_12_months_avg = city_data.tail(12).mean()\n",
        "\n",
        "  # 예측값을 최소 0, 최대 최근 12개월 평균의 3배로 클리핑\n",
        "  predicted_value_clipped = np.clip(predicted_value, recent_12_months_avg*0.1, recent_12_months_avg * 5)\n",
        "\n",
        "  # 결과를 DataFrame에 추가\n",
        "  city_result = pd.DataFrame({\n",
        "      'City': city,\n",
        "      'Date': date_range,\n",
        "      'People': predicted_value_clipped\n",
        "  })\n",
        "\n",
        "  result_df = result_df.append(city_result, ignore_index=True)\n",
        "\n",
        "result_df['People'] = result_df['People'].astype(int)\n",
        "\n",
        "# 딕셔너리를 파일로 저장\n",
        "with open('/content/gdrive/MyDrive/Colab Notebooks/bigdata/models/city_models.pkl', 'wb') as models_file:\n",
        "    pickle.dump(city_models, models_file)\n",
        "\n",
        "# 결과를 CSV 파일로 저장\n",
        "result_df.to_csv('/content/gdrive/MyDrive/Colab Notebooks/bigdata/predicted_travelers.csv', index=False, encoding=\"utf-8-sig\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
